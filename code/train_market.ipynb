{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd117a25-51f7-4b37-80dd-57601c645fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, math, time, argparse, os\n",
    "import random, dataset, utils, losses, net\n",
    "import numpy as np\n",
    "\n",
    "from dataset.market import Market\n",
    "from net.resnet import *\n",
    "from net.googlenet import *\n",
    "from net.bn_inception import *\n",
    "from dataset import sampler\n",
    "from torch.utils.data.sampler import BatchSampler\n",
    "from torch.utils.data.dataloader import default_collate\n",
    "\n",
    "from tqdm import *\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b68c83a-1a81-444f-aa00-51349c5ecca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0de986bb-fec0-4e9a-b128-8144593a4615",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG_DIR = '.'\n",
    "trn_dataset = dataset.load('market', '../../Market-1501-v15.09.15/', 'train', transform = dataset.utils.make_transform(\n",
    "                                                                                                                        is_train = True, \n",
    "                                                                                                                        is_inception = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe096192-8b04-4ee1-8e3e-0e9ce965ec0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_tr = torch.utils.data.DataLoader(\n",
    "        trn_dataset,\n",
    "        batch_size = 50,\n",
    "        shuffle = True,\n",
    "        num_workers = 4,\n",
    "        drop_last = True,\n",
    "        pin_memory = True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e09b2d13-d22e-4d91-a519-a8971ba45bad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nevin/anaconda3/envs/cv/lib/python3.9/site-packages/torchvision/models/_utils.py:135: UserWarning: Using 'weights' as positional parameter(s) is deprecated since 0.13 and may be removed in the future. Please use keyword parameter(s) instead.\n",
      "  warnings.warn(\n",
      "/home/nevin/anaconda3/envs/cv/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model = Resnet50(embedding_size=512, pretrained=True, is_norm=1, bn_freeze =1).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa815ea5-c86f-4e64-9dfb-bdd71319837c",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = losses.Proxy_Anchor(nb_classes = trn_dataset.nb_classes(), sz_embed = 512, mrg = 0.1, alpha = 32).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d82987f-a60d-4672-8eb6-cc87035cb22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_groups = [\n",
    "    {'params': list(set(model.parameters()).difference(set(model.model.embedding.parameters())))},\n",
    "    {'params': model.model.embedding.parameters(), 'lr':float(1e-4) * 1},\n",
    "]\n",
    "param_groups.append({'params': criterion.parameters(), 'lr':float(1e-4) * 100})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39029af3-6b21-4cd2-8dd0-d3d1db46d109",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = torch.optim.AdamW(param_groups, lr=float(1e-4), weight_decay = 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00b75ef9-d5d0-48c1-a6fa-d80b64139414",
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = torch.optim.lr_scheduler.StepLR(opt, step_size=10, gamma = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "405de8ba-1e69-4f04-9b8a-1d995e5cfa7e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/home/nevin/anaconda3/envs/cv/lib/python3.9/site-packages/torch/nn/modules/conv.py:456: UserWarning: Applied workaround for CuDNN issue, install nvrtc.so (Triggered internally at /opt/conda/conda-bld/pytorch_1695392022560/work/aten/src/ATen/native/cudnn/Conv_v8.cpp:80.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "Train Epoch: 0 [44/44 (98%)] Loss: 7.966811: : 44it [00:04,  9.33it/s] \n",
      "Train Epoch: 1 [44/44 (98%)] Loss: 7.491183: : 44it [00:11,  3.71it/s]\n",
      "Train Epoch: 2 [44/44 (98%)] Loss: 7.233761: : 44it [00:11,  3.74it/s]\n",
      "Train Epoch: 3 [44/44 (98%)] Loss: 6.655641: : 44it [00:11,  3.74it/s]\n",
      "Train Epoch: 4 [44/44 (98%)] Loss: 4.952507: : 44it [00:11,  3.74it/s]\n",
      "Train Epoch: 5 [44/44 (98%)] Loss: 5.777985: : 44it [00:11,  3.74it/s]\n",
      "Train Epoch: 6 [44/44 (98%)] Loss: 4.920753: : 44it [00:11,  3.74it/s]\n",
      "Train Epoch: 7 [44/44 (98%)] Loss: 4.813202: : 44it [00:11,  3.74it/s]\n",
      "Train Epoch: 8 [44/44 (98%)] Loss: 4.158882: : 44it [00:11,  3.75it/s]\n",
      "Train Epoch: 9 [44/44 (98%)] Loss: 4.067470: : 44it [00:11,  3.74it/s]\n",
      "Train Epoch: 10 [44/44 (98%)] Loss: 3.607781: : 44it [00:11,  3.74it/s]\n",
      "Train Epoch: 11 [44/44 (98%)] Loss: 4.016815: : 44it [00:11,  3.74it/s]\n",
      "Train Epoch: 12 [44/44 (98%)] Loss: 4.021202: : 44it [00:11,  3.74it/s]\n",
      "Train Epoch: 13 [44/44 (98%)] Loss: 3.039400: : 44it [00:11,  3.74it/s]\n",
      "Train Epoch: 14 [44/44 (98%)] Loss: 3.718045: : 44it [00:11,  3.74it/s]\n",
      "Train Epoch: 15 [44/44 (98%)] Loss: 3.811115: : 44it [00:11,  3.75it/s]\n",
      "Train Epoch: 16 [44/44 (98%)] Loss: 3.172296: : 44it [00:11,  3.74it/s]\n",
      "Train Epoch: 17 [44/44 (98%)] Loss: 3.061584: : 44it [00:11,  3.74it/s]\n",
      "Train Epoch: 18 [44/44 (98%)] Loss: 2.875965: : 44it [00:11,  3.74it/s]\n",
      "Train Epoch: 19 [44/44 (98%)] Loss: 2.542943: : 44it [00:11,  3.74it/s]\n",
      "Train Epoch: 20 [44/44 (98%)] Loss: 2.818958: : 44it [00:11,  3.73it/s]\n",
      "Train Epoch: 21 [44/44 (98%)] Loss: 2.674109: : 44it [00:11,  3.73it/s]\n",
      "Train Epoch: 22 [44/44 (98%)] Loss: 2.897043: : 44it [00:11,  3.73it/s]\n",
      "Train Epoch: 23 [44/44 (98%)] Loss: 2.485187: : 44it [00:11,  3.74it/s]\n",
      "Train Epoch: 24 [44/44 (98%)] Loss: 2.040915: : 44it [00:11,  3.74it/s]\n",
      "Train Epoch: 25 [44/44 (98%)] Loss: 3.260785: : 44it [00:11,  3.74it/s]\n",
      "Train Epoch: 26 [44/44 (98%)] Loss: 1.962540: : 44it [00:12,  3.66it/s]\n",
      "Train Epoch: 27 [44/44 (98%)] Loss: 2.416421: : 44it [00:11,  3.82it/s]\n",
      "Train Epoch: 28 [44/44 (98%)] Loss: 3.606498: : 44it [00:11,  3.82it/s]\n",
      "Train Epoch: 29 [44/44 (98%)] Loss: 2.182796: : 44it [00:11,  3.81it/s]\n",
      "Train Epoch: 30 [44/44 (98%)] Loss: 2.137567: : 44it [00:11,  3.81it/s]\n",
      "Train Epoch: 31 [44/44 (98%)] Loss: 1.667197: : 44it [00:11,  3.81it/s]\n",
      "Train Epoch: 32 [44/44 (98%)] Loss: 2.329812: : 44it [00:11,  3.81it/s]\n",
      "Train Epoch: 33 [44/44 (98%)] Loss: 2.035198: : 44it [00:11,  3.81it/s]\n",
      "Train Epoch: 34 [44/44 (98%)] Loss: 1.454140: : 44it [00:11,  3.81it/s]\n",
      "Train Epoch: 35 [44/44 (98%)] Loss: 1.713463: : 44it [00:11,  3.81it/s]\n",
      "Train Epoch: 36 [44/44 (98%)] Loss: 1.177291: : 44it [00:11,  3.81it/s]\n",
      "Train Epoch: 37 [44/44 (98%)] Loss: 2.625182: : 44it [00:11,  3.81it/s]\n",
      "Train Epoch: 38 [44/44 (98%)] Loss: 2.160698: : 44it [00:11,  3.81it/s]\n",
      "Train Epoch: 39 [44/44 (98%)] Loss: 2.925379: : 44it [00:11,  3.82it/s]\n",
      "Train Epoch: 40 [44/44 (98%)] Loss: 1.810529: : 44it [00:11,  3.81it/s]\n",
      "Train Epoch: 41 [44/44 (98%)] Loss: 2.239534: : 44it [00:11,  3.81it/s]\n",
      "Train Epoch: 42 [44/44 (98%)] Loss: 1.984950: : 44it [00:11,  3.81it/s]\n",
      "Train Epoch: 43 [44/44 (98%)] Loss: 1.775412: : 44it [00:11,  3.81it/s]\n",
      "Train Epoch: 44 [44/44 (98%)] Loss: 1.653275: : 44it [00:11,  3.81it/s]\n",
      "Train Epoch: 45 [44/44 (98%)] Loss: 1.576518: : 44it [00:11,  3.81it/s]\n",
      "Train Epoch: 46 [44/44 (98%)] Loss: 1.260459: : 44it [00:11,  3.82it/s]\n",
      "Train Epoch: 47 [44/44 (98%)] Loss: 2.442680: : 44it [00:11,  3.81it/s]\n",
      "Train Epoch: 48 [44/44 (98%)] Loss: 1.453201: : 44it [00:11,  3.81it/s]\n",
      "Train Epoch: 49 [44/44 (98%)] Loss: 1.071803: : 44it [00:11,  3.82it/s]\n",
      "Train Epoch: 50 [44/44 (98%)] Loss: 1.328114: : 44it [00:11,  3.81it/s]\n",
      "Train Epoch: 51 [44/44 (98%)] Loss: 1.872879: : 44it [00:11,  3.82it/s]\n",
      "Train Epoch: 52 [44/44 (98%)] Loss: 1.391626: : 44it [00:11,  3.81it/s]\n",
      "Train Epoch: 53 [44/44 (98%)] Loss: 1.209646: : 44it [00:11,  3.82it/s]\n",
      "Train Epoch: 54 [44/44 (98%)] Loss: 1.623008: : 44it [00:11,  3.82it/s]\n",
      "Train Epoch: 55 [44/44 (98%)] Loss: 0.833656: : 44it [00:11,  3.81it/s]\n",
      "Train Epoch: 56 [44/44 (98%)] Loss: 2.102965: : 44it [00:11,  3.82it/s]\n",
      "Train Epoch: 57 [44/44 (98%)] Loss: 1.601245: : 44it [00:11,  3.82it/s]\n",
      "Train Epoch: 58 [44/44 (98%)] Loss: 1.327172: : 44it [00:11,  3.82it/s]\n",
      "Train Epoch: 59 [44/44 (98%)] Loss: 1.531469: : 44it [00:11,  3.81it/s]\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(0, 60):\n",
    "    model.train()\n",
    "    bn_freeze = True\n",
    "\n",
    "    if bn_freeze:\n",
    "            modules = model.model.modules()\n",
    "            for m in modules: \n",
    "                if isinstance(m, nn.BatchNorm2d):\n",
    "                    m.eval()\n",
    "\n",
    "    losses_per_epoch = []\n",
    "    unfreeze_model_param = list(model.model.embedding.parameters()) + list(criterion.parameters())\n",
    "\n",
    "    if epoch == 0:\n",
    "        for param in list(set(model.parameters()).difference(set(unfreeze_model_param))):\n",
    "            param.requires_grad = False\n",
    "    if epoch == 1:\n",
    "        for param in list(set(model.parameters()).difference(set(unfreeze_model_param))):\n",
    "            param.requires_grad = True\n",
    "\n",
    "    pbar = tqdm(enumerate(dl_tr))\n",
    "\n",
    "    for batch_idx, (x, y) in pbar:                         \n",
    "        m = model(x.squeeze().cuda())\n",
    "        loss = criterion(m, y.squeeze().cuda())\n",
    "        \n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        torch.nn.utils.clip_grad_value_(model.parameters(), 10)\n",
    "        \n",
    "        torch.nn.utils.clip_grad_value_(criterion.parameters(), 10)\n",
    "\n",
    "        losses_per_epoch.append(loss.data.cpu().numpy())\n",
    "        opt.step()\n",
    "\n",
    "        pbar.set_description(\n",
    "            'Train Epoch: {} [{}/{} ({:.0f}%)] Loss: {:.6f}'.format(\n",
    "                epoch, batch_idx + 1, len(dl_tr),\n",
    "                100. * batch_idx / len(dl_tr),\n",
    "                loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "43693b09-1140-4b30-b00a-99d78b0b4fe5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Resnet50(\n",
       "  (model): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       "    (gap): AdaptiveAvgPool2d(output_size=1)\n",
       "    (gmp): AdaptiveMaxPool2d(output_size=1)\n",
       "    (embedding): Linear(in_features=2048, out_features=512, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "26afe4e5-bb01-4620-a361-9f830c32c590",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dataset = dataset.load('market', '../../Market-1501-v15.09.15/', 'train', transform = dataset.utils.make_transform(\n",
    "                                                                                                                        is_train = False, \n",
    "                                                                                                                        is_inception = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0b915fa4-6f95-4fe0-b50a-4e38f3040733",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset.base import BaseDataset\n",
    "\n",
    "class Market(BaseDataset):\n",
    "    def __init__(self, root, mode, transform = None):\n",
    "        self.root = root\n",
    "        self.mode = mode\n",
    "\n",
    "        gt_bbox = [os.path.join(self.root, 'gt_bbox', x) for x in os.listdir(os.path.join(self.root, 'gt_bbox'))]\n",
    "        bbox_train = [os.path.join(self.root, 'bounding_box_train', x) for x in os.listdir(os.path.join(self.root, 'bounding_box_train'))]\n",
    "        self.train_images = gt_bbox + bbox_train\n",
    "        \n",
    "        self.transform = transform\n",
    "        if self.mode == 'train':\n",
    "            self.classes = range(0,100)\n",
    "        elif self.mode == 'eval':\n",
    "            self.classes = range(1000,1501)\n",
    "                \n",
    "        BaseDataset.__init__(self, self.root, self.mode, self.transform)\n",
    "        \n",
    "        ys = [int(image.split('/')[-1].split('_')[0]) for image in self.train_images]\n",
    "        index = 0\n",
    "        self.im_paths = []\n",
    "        for im_path, y in zip(self.train_images, ys):\n",
    "            if y in self.classes: # choose only specified classes\n",
    "                self.im_paths.append(im_path)\n",
    "                self.ys.append(y)\n",
    "                self.I += [index]\n",
    "                index += 1\n",
    "\n",
    "    def set_one_class(self, class_label):\n",
    "        \n",
    "        self.ys = []\n",
    "        self.im_paths = []\n",
    "        self.I = []\n",
    "        ys = [int(image.split('/')[-1].split('_')[0]) for image in self.train_images]\n",
    "        index = 0\n",
    "        for im_path, y in zip(self.train_images, ys):\n",
    "            if y ==class_label: # choose only specified classes\n",
    "                self.im_paths.append(im_path)\n",
    "                self.ys.append(y)\n",
    "                self.I += [index]\n",
    "                index += 1\n",
    "    def reset(self):\n",
    "        self.__init__(self.root, self.mode, self.transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2b3601d5-5b93-48d8-8756-5bd9202b19d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = Market('../../Market-1501-v15.09.15/', 'eval', dataset.utils.make_transform(is_train = False, is_inception = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e9fef739-192b-4c10-abb6-07e61115e61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "d.set_one_class(1070)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1b5a6175-f13a-4d3a-a2ba-1e5ef974ee84",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "for images, labels in dl_ev:\n",
    "    embs_pred_2 = model(images.squeeze().cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ff9b4c3a-9af1-4e9e-ab8d-32e515fa36f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "d.set_one_class(1200)\n",
    "\n",
    "dl_ev = torch.utils.data.DataLoader(\n",
    "        d,\n",
    "        batch_size = len(d),\n",
    "        shuffle = True,\n",
    "        num_workers = 4,\n",
    "        drop_last = True,\n",
    "        pin_memory = True\n",
    ")\n",
    "model.eval()\n",
    "for images, labels in dl_ev:\n",
    "    embs_pred_1 = model(images.squeeze().cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "8508e288-a096-4650-8fb5-dea14bf8ff33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.8198, 0.8986, 0.5389, 0.4660, 0.8786, 0.5574, 0.4878, 0.7150,\n",
       "         0.7501, 0.4738, 0.8181, 0.6980, 0.7948, 0.5061, 0.6141, 0.5627, 0.5643,\n",
       "         0.5660, 0.4125, 0.4872, 0.5157, 0.4867, 0.8246, 0.5339, 0.4964, 0.5338,\n",
       "         0.7170, 0.8414, 0.7112, 0.8509]], device='cuda:0',\n",
       "       grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.linear(embs_pred_1[0].reshape(1, 512), embs_pred_1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
