{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd117a25-51f7-4b37-80dd-57601c645fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, math, time, argparse, os\n",
    "import random, dataset, utils, losses, net\n",
    "import numpy as np\n",
    "\n",
    "from dataset.Inshop import Inshop_Dataset\n",
    "from net.resnet import *\n",
    "from net.googlenet import *\n",
    "from net.bn_inception import *\n",
    "from dataset import sampler\n",
    "from torch.utils.data.sampler import BatchSampler\n",
    "from torch.utils.data.dataloader import default_collate\n",
    "\n",
    "from tqdm import *\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b68c83a-1a81-444f-aa00-51349c5ecca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0de986bb-fec0-4e9a-b128-8144593a4615",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG_DIR = '.'\n",
    "trn_dataset = dataset.load('market', '../../Market-1501-v15.09.15/', 'train', transform = dataset.utils.make_transform(\n",
    "                                                                                                                        is_train = True, \n",
    "                                                                                                                        is_inception = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe096192-8b04-4ee1-8e3e-0e9ce965ec0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_tr = torch.utils.data.DataLoader(\n",
    "        trn_dataset,\n",
    "        batch_size = 50,\n",
    "        shuffle = True,\n",
    "        num_workers = 4,\n",
    "        drop_last = True,\n",
    "        pin_memory = True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e09b2d13-d22e-4d91-a519-a8971ba45bad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nevin/anaconda3/envs/cv/lib/python3.9/site-packages/torchvision/models/_utils.py:135: UserWarning: Using 'weights' as positional parameter(s) is deprecated since 0.13 and may be removed in the future. Please use keyword parameter(s) instead.\n",
      "  warnings.warn(\n",
      "/home/nevin/anaconda3/envs/cv/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model = Resnet50(embedding_size=512, pretrained=True, is_norm=1, bn_freeze =1).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa815ea5-c86f-4e64-9dfb-bdd71319837c",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = losses.Proxy_Anchor(nb_classes = trn_dataset.nb_classes(), sz_embed = 512, mrg = 0.1, alpha = 32).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d82987f-a60d-4672-8eb6-cc87035cb22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_groups = [\n",
    "    {'params': list(set(model.parameters()).difference(set(model.model.embedding.parameters())))},\n",
    "    {'params': model.model.embedding.parameters(), 'lr':float(1e-4) * 1},\n",
    "]\n",
    "param_groups.append({'params': criterion.parameters(), 'lr':float(1e-4) * 100})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39029af3-6b21-4cd2-8dd0-d3d1db46d109",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = torch.optim.AdamW(param_groups, lr=float(1e-4), weight_decay = 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00b75ef9-d5d0-48c1-a6fa-d80b64139414",
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = torch.optim.lr_scheduler.StepLR(opt, step_size=10, gamma = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "405de8ba-1e69-4f04-9b8a-1d995e5cfa7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/home/nevin/anaconda3/envs/cv/lib/python3.9/site-packages/torch/nn/modules/conv.py:456: UserWarning: Applied workaround for CuDNN issue, install nvrtc.so (Triggered internally at /opt/conda/conda-bld/pytorch_1695392022560/work/aten/src/ATen/native/cudnn/Conv_v8.cpp:80.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "Train Epoch: 0 [44/44 (98%)] Loss: 7.966811: : 44it [00:04,  9.89it/s] \n",
      "Train Epoch: 1 [44/44 (98%)] Loss: 7.550196: : 44it [00:12,  3.63it/s]\n",
      "Train Epoch: 2 [44/44 (98%)] Loss: 7.102752: : 44it [00:11,  3.69it/s]\n",
      "Train Epoch: 3 [44/44 (98%)] Loss: 6.702276: : 44it [00:11,  3.69it/s]\n",
      "Train Epoch: 4 [44/44 (98%)] Loss: 5.151131: : 44it [00:11,  3.69it/s]\n",
      "Train Epoch: 5 [44/44 (98%)] Loss: 5.675545: : 44it [00:11,  3.68it/s]\n",
      "Train Epoch: 6 [44/44 (98%)] Loss: 5.242073: : 44it [00:11,  3.68it/s]\n",
      "Train Epoch: 7 [44/44 (98%)] Loss: 5.262970: : 44it [00:11,  3.69it/s]\n",
      "Train Epoch: 8 [44/44 (98%)] Loss: 4.065011: : 44it [00:11,  3.69it/s]\n",
      "Train Epoch: 9 [44/44 (98%)] Loss: 3.869186: : 44it [00:11,  3.68it/s]\n",
      "Train Epoch: 10 [44/44 (98%)] Loss: 3.893627: : 44it [00:11,  3.68it/s]\n",
      "Train Epoch: 11 [44/44 (98%)] Loss: 4.287508: : 44it [00:11,  3.67it/s]\n",
      "Train Epoch: 12 [44/44 (98%)] Loss: 3.758739: : 44it [00:11,  3.68it/s]\n",
      "Train Epoch: 13 [44/44 (98%)] Loss: 3.491555: : 44it [00:11,  3.67it/s]\n",
      "Train Epoch: 14 [44/44 (98%)] Loss: 4.001197: : 44it [00:11,  3.68it/s]\n",
      "Train Epoch: 15 [44/44 (98%)] Loss: 3.601406: : 44it [00:11,  3.68it/s]\n",
      "Train Epoch: 16 [44/44 (98%)] Loss: 3.111202: : 44it [00:12,  3.66it/s]\n",
      "Train Epoch: 17 [44/44 (98%)] Loss: 3.241221: : 44it [00:12,  3.66it/s]\n",
      "Train Epoch: 18 [44/44 (98%)] Loss: 3.220307: : 44it [00:11,  3.67it/s]\n",
      "Train Epoch: 19 [44/44 (98%)] Loss: 3.037902: : 44it [00:12,  3.62it/s]\n",
      "Train Epoch: 20 [44/44 (98%)] Loss: 2.791316: : 44it [00:12,  3.57it/s]\n",
      "Train Epoch: 21 [44/44 (98%)] Loss: 2.883046: : 44it [00:12,  3.62it/s]\n",
      "Train Epoch: 22 [44/44 (98%)] Loss: 2.628935: : 44it [00:11,  3.71it/s]\n",
      "Train Epoch: 23 [44/44 (98%)] Loss: 2.311059: : 44it [00:11,  3.71it/s]\n",
      "Train Epoch: 24 [44/44 (98%)] Loss: 2.290088: : 44it [00:11,  3.70it/s]\n",
      "Train Epoch: 25 [44/44 (98%)] Loss: 3.154405: : 44it [00:11,  3.69it/s]\n",
      "Train Epoch: 26 [44/44 (98%)] Loss: 1.989022: : 44it [00:12,  3.64it/s]\n",
      "Train Epoch: 27 [44/44 (98%)] Loss: 2.705940: : 44it [00:12,  3.52it/s]\n",
      "Train Epoch: 28 [44/44 (98%)] Loss: 3.678033: : 44it [00:12,  3.59it/s]\n",
      "Train Epoch: 29 [44/44 (98%)] Loss: 2.788122: : 44it [00:12,  3.56it/s]\n",
      "Train Epoch: 30 [44/44 (98%)] Loss: 1.858448: : 44it [00:12,  3.48it/s]\n",
      "Train Epoch: 31 [44/44 (98%)] Loss: 1.593022: : 44it [00:12,  3.46it/s]\n",
      "Train Epoch: 32 [44/44 (98%)] Loss: 1.828283: : 44it [00:11,  3.68it/s]\n",
      "Train Epoch: 33 [44/44 (98%)] Loss: 1.818398: : 44it [00:11,  3.73it/s]\n",
      "Train Epoch: 34 [44/44 (98%)] Loss: 1.198292: : 44it [00:11,  3.71it/s]\n",
      "Train Epoch: 35 [44/44 (98%)] Loss: 1.945329: : 44it [00:11,  3.72it/s]\n",
      "Train Epoch: 36 [44/44 (98%)] Loss: 1.248702: : 44it [00:11,  3.72it/s]\n",
      "Train Epoch: 37 [44/44 (98%)] Loss: 3.052990: : 44it [00:11,  3.73it/s]\n",
      "Train Epoch: 38 [44/44 (98%)] Loss: 2.187655: : 44it [00:11,  3.72it/s]\n",
      "Train Epoch: 39 [44/44 (98%)] Loss: 3.115506: : 44it [00:11,  3.71it/s]\n",
      "Train Epoch: 40 [44/44 (98%)] Loss: 1.691254: : 44it [00:11,  3.72it/s]\n",
      "Train Epoch: 41 [44/44 (98%)] Loss: 1.647313: : 44it [00:11,  3.72it/s]\n",
      "Train Epoch: 42 [44/44 (98%)] Loss: 1.216301: : 44it [00:11,  3.71it/s]\n",
      "Train Epoch: 43 [44/44 (98%)] Loss: 1.432276: : 44it [00:11,  3.71it/s]\n",
      "Train Epoch: 44 [44/44 (98%)] Loss: 1.688811: : 44it [00:11,  3.72it/s]\n",
      "Train Epoch: 45 [44/44 (98%)] Loss: 1.334170: : 44it [00:11,  3.72it/s]\n",
      "Train Epoch: 46 [44/44 (98%)] Loss: 1.127568: : 44it [00:11,  3.71it/s]\n",
      "Train Epoch: 47 [44/44 (98%)] Loss: 2.282643: : 44it [00:11,  3.72it/s]\n",
      "Train Epoch: 48 [44/44 (98%)] Loss: 1.970572: : 44it [00:11,  3.71it/s]\n",
      "Train Epoch: 49 [44/44 (98%)] Loss: 1.123898: : 44it [00:11,  3.72it/s]\n",
      "Train Epoch: 50 [44/44 (98%)] Loss: 1.942154: : 44it [00:11,  3.72it/s]\n",
      "Train Epoch: 51 [44/44 (98%)] Loss: 1.505122: : 44it [00:11,  3.70it/s]\n",
      "Train Epoch: 52 [44/44 (98%)] Loss: 1.312598: : 44it [00:12,  3.60it/s]\n",
      "Train Epoch: 53 [44/44 (98%)] Loss: 1.675954: : 44it [00:12,  3.62it/s]\n",
      "Train Epoch: 54 [44/44 (98%)] Loss: 1.796332: : 44it [00:12,  3.63it/s]\n",
      "Train Epoch: 55 [44/44 (98%)] Loss: 1.174293: : 44it [00:12,  3.63it/s]\n",
      "Train Epoch: 56 [44/44 (98%)] Loss: 1.969042: : 44it [00:12,  3.63it/s]\n",
      "Train Epoch: 57 [44/44 (98%)] Loss: 1.645166: : 44it [00:12,  3.62it/s]\n",
      "Train Epoch: 58 [44/44 (98%)] Loss: 1.685177: : 44it [00:12,  3.61it/s]\n",
      "Train Epoch: 59 [44/44 (98%)] Loss: 1.503048: : 44it [00:11,  3.70it/s]\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(0, 60):\n",
    "    model.train()\n",
    "    bn_freeze = True\n",
    "\n",
    "    if bn_freeze:\n",
    "            modules = model.model.modules()\n",
    "            for m in modules: \n",
    "                if isinstance(m, nn.BatchNorm2d):\n",
    "                    m.eval()\n",
    "\n",
    "    losses_per_epoch = []\n",
    "    unfreeze_model_param = list(model.model.embedding.parameters()) + list(criterion.parameters())\n",
    "\n",
    "    if epoch == 0:\n",
    "        for param in list(set(model.parameters()).difference(set(unfreeze_model_param))):\n",
    "            param.requires_grad = False\n",
    "    if epoch == 1:\n",
    "        for param in list(set(model.parameters()).difference(set(unfreeze_model_param))):\n",
    "            param.requires_grad = True\n",
    "\n",
    "    pbar = tqdm(enumerate(dl_tr))\n",
    "\n",
    "    for batch_idx, (x, y) in pbar:                         \n",
    "        m = model(x.squeeze().cuda())\n",
    "        loss = criterion(m, y.squeeze().cuda())\n",
    "        \n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        torch.nn.utils.clip_grad_value_(model.parameters(), 10)\n",
    "        \n",
    "        torch.nn.utils.clip_grad_value_(criterion.parameters(), 10)\n",
    "\n",
    "        losses_per_epoch.append(loss.data.cpu().numpy())\n",
    "        opt.step()\n",
    "\n",
    "        pbar.set_description(\n",
    "            'Train Epoch: {} [{}/{} ({:.0f}%)] Loss: {:.6f}'.format(\n",
    "                epoch, batch_idx + 1, len(dl_tr),\n",
    "                100. * batch_idx / len(dl_tr),\n",
    "                loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43693b09-1140-4b30-b00a-99d78b0b4fe5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
